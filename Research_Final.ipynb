{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4UIswgulxzWN",
        "outputId": "c6ada393-07cd-4965-f2af-9d00902a4217"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fastapi\n",
            "  Downloading fastapi-0.112.1-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.30.6-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Collecting openai\n",
            "  Downloading openai-1.42.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting pyunsplash\n",
            "  Downloading pyunsplash-1.0.0rc2.tar.gz (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting starlette<0.39.0,>=0.37.2 (from fastapi)\n",
            "  Downloading starlette-0.38.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.12.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pyunsplash) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pyunsplash) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pyunsplash) (2.0.7)\n",
            "Downloading fastapi-0.112.1-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.30.6-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.0-py3-none-any.whl (22 kB)\n",
            "Downloading openai-1.42.0-py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.9/362.9 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.38.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyunsplash\n",
            "  Building wheel for pyunsplash (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyunsplash: filename=pyunsplash-1.0.0rc2-py3-none-any.whl size=12968 sha256=8d17deda41a076b8f56d799ffba067ffb48179ce4be79c48b03bcba3fc048967\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/f7/7d/878ade22be264d33306f00c0cd0451ada5e3e2aa5671bd3dbb\n",
            "Successfully built pyunsplash\n",
            "Installing collected packages: pyngrok, jiter, h11, uvicorn, starlette, pyunsplash, httpcore, httpx, fastapi, openai\n",
            "Successfully installed fastapi-0.112.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jiter-0.5.0 openai-1.42.0 pyngrok-7.2.0 pyunsplash-1.0.0rc2 starlette-0.38.2 uvicorn-0.30.6\n"
          ]
        }
      ],
      "source": [
        "!pip install fastapi uvicorn pyngrok nest_asyncio openai pyunsplash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ndoieHg022E"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "from pyngrok import ngrok\n",
        "from fastapi import FastAPI\n",
        "from fastapi.responses import JSONResponse\n",
        "import uvicorn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFlIPlwExzWP"
      },
      "outputs": [],
      "source": [
        "# @title Demo\n",
        "import nest_asyncio\n",
        "import uvicorn\n",
        "from fastapi import FastAPI, Query\n",
        "from fastapi.responses import JSONResponse, FileResponse\n",
        "from typing import Optional\n",
        "# Patch the event loop\n",
        "nest_asyncio.apply()\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "@app.get(\"/status\")\n",
        "async def status_check():\n",
        "    return JSONResponse(content={\"status\": \"API is running\"})\n",
        "\n",
        "@app.get(\"/recommend_images\")\n",
        "async def recommend_images(query: Optional[str] = Query(None, description=\"Query string for image recommendation\")):\n",
        "    # Based on the query, recommend an image. Here, we're just returning a static file as an example.\n",
        "    image_path = \"/content/image1.png\"  # Replace with logic to select the appropriate image\n",
        "    return FileResponse(image_path, media_type=\"image/png\")\n",
        "\n",
        "@app.get(\"/recommend_video\")\n",
        "async def recommend_video(query: Optional[str] = Query(None, description=\"Query string for video recommendation\")):\n",
        "    # Based on the query, recommend a video. Here, we're just returning a static file as an example.\n",
        "    video_path = \"/content/video1.mp4\"  # Replace with logic to select the appropriate video\n",
        "    return FileResponse(video_path, media_type=\"video/mp4\")\n",
        "\n",
        "public_url = ngrok.connect(8000)\n",
        "print(public_url)\n",
        "# Run the Uvicorn server\n",
        "uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBTd_ml31nFB"
      },
      "source": [
        "# Logic Development"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYQ_leqEq-6U"
      },
      "outputs": [],
      "source": [
        "# @title Keyword Extraction\n",
        "from openai import OpenAI\n",
        "client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=(\"APIKEYHERE\")\n",
        "def analyze_text_for_keywords(content: str):\n",
        "    \"\"\"\n",
        "    Analyzes the provided text to extract keywords using the OpenAI API.\n",
        "    \"\"\"\n",
        "    client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=userdata.get('OPENAI_KEY'),\n",
        "    )\n",
        "    prompt = f\"Analyze the following text and generate a list of keywords: {content}\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a keyword extraction assistant,  Understand the context and its supposed to be used to find sutable images, add relevant additional keywords based on the scenario which can be used while searching the image. Only return sutable text that is needed to search the image, make sure to highlight the main object of the context, return only string of search\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    keywords = response.choices[0].message\n",
        "    keywords = keywords.content\n",
        "\n",
        "    return keywords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zGmfv-srb1u",
        "outputId": "181aff0f-61df-43d3-d402-dd450be88e9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "big bug, insect, critter, macro photography, wildlife, nature, pests\n"
          ]
        }
      ],
      "source": [
        "api_response = analyze_text_for_keywords(\"Hi this is a very big bug\")\n",
        "print(api_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xr6V_2eR60cm"
      },
      "outputs": [],
      "source": [
        "# @title  AI Image Prompt Generator\n",
        "def generate_ai_image_prompt(content: str):\n",
        "    \"\"\"\n",
        "    Generates a detailed prompt for AI image generation based on the text content.\n",
        "    \"\"\"\n",
        "    prompt = f\"Create a detailed and specific image generation prompt for the following content: {content}\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a AI Image Prompt Generator. Provide Prompts to generate image in DALLE using Photo Realistic Images with real world lighting , be very technical with the camera settings, it should not feel like an AI generated image, Will pass the content generate the prompt accordingly,  must be under 200 tokens in total , add negative prompts to remove unwanted artifacts use 100 tokens for positive pompt and 100 for  negative prompt to remove artifacting, only return just the prompt and no other text\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    imageprompt = response.choices[0].message\n",
        "    imageprompt = imageprompt.content\n",
        "    return imageprompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_p_U3UQ61lh"
      },
      "outputs": [],
      "source": [
        "PROMPT = generate_ai_image_prompt(\"There was a little boy who loved to come and play around the tree every day. He used to climb to the treetop, eat the apples, and take naps under its shade. He loved the tree and the tree also loved to play with him. As time went by, the little boy grew up and he would no longer play around the tree every day.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4k3tR3328vsA"
      },
      "outputs": [],
      "source": [
        "PROMPT = \"\"\"**Positive Prompt:** A young boy playing joyfully around a large, lush green tree in a sunlit park. The boy is climbing to the treetop, his face beaming with happiness, surrounded by vibrant red apples hanging from the branches. In the foreground, soft sunlight filters through the leaves, creating dappled shadows on the ground. The scene captures the essence of childhood joy and friendship with nature. Camera settings: 50mm lens, f/2.8 aperture, ISO 100, 1/200s shutter speed for sharp details and soft background blur.\n",
        "\n",
        "**Negative Prompt:** Remove any unnatural textures, stark shadows, pixelation, or distortion in the tree and boy. Exclude any harsh lighting, overly saturated colors, or visible digital artifacts. Avoid unrealistic proportions or perspectives, and ensure no ghosting effects or unwanted lens flares in the scene.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hV_h-xKj3tw-"
      },
      "outputs": [],
      "source": [
        "# @title AI Image Generation\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "def generate_ai_image(PROMPT: str):\n",
        "    \"\"\"\n",
        "    Generates images using the OpenAI API based on the provided prompt.\n",
        "    \"\"\"\n",
        "    client = OpenAI(\n",
        "        # This is the default and can be omitted\n",
        "        api_key=userdata.get('OPENAI_KEY'),\n",
        "        )\n",
        "    response = client.images.generate(\n",
        "      model=\"dall-e-3\",\n",
        "      prompt=PROMPT,\n",
        "      size=\"1024x1024\",\n",
        "      n=1,\n",
        "    )\n",
        "\n",
        "    url = response.data[0].url\n",
        "    return url\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0uuHktBlyAQ",
        "outputId": "c322271b-7e75-474a-f092-3d3b01e6cedc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://oaidalleapiprodscus.blob.core.windows.net/private/org-vA4Uor6dRcDGllOLlqOvuUEH/user-4jRL43H2e9BoqaoOH9DVjiGX/img-9Fqo6BTP4EJ5Ubxt6VaTSnSG.png?st=2024-08-24T07%3A55%3A13Z&se=2024-08-24T09%3A55%3A13Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-08-23T23%3A30%3A00Z&ske=2024-08-24T23%3A30%3A00Z&sks=b&skv=2024-08-04&sig=NUuEAXyt%2Bpz9t82y1e/UIqtq6cbAHzsanSbNNgd78AU%3D\n"
          ]
        }
      ],
      "source": [
        "print(generate_ai_image(PROMPT))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veV2Ej8W-tmS"
      },
      "outputs": [],
      "source": [
        "# @title Unsplashed API\n",
        "from pyunsplash import PyUnsplash\n",
        "unsplash_api_key = userdata.get('unsplash_api_key')\n",
        "\n",
        "pu = PyUnsplash(api_key=unsplash_api_key)\n",
        "\n",
        "def fetch_unsplash_images(keywords: str):\n",
        "    \"\"\"\n",
        "    Fetches images from Unsplash based on the provided keywords using PyUnsplash.\n",
        "    \"\"\"\n",
        "    #loop through the list and get the images\n",
        "    search = pu.search(type_=\"photos\", query=keywords, per_page=1)\n",
        "    images = [photo.link_download for photo in search.entries]\n",
        "    return images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXWBLii8_Ar7",
        "outputId": "bed416c9-6b51-42bb-d839-ba070429d73f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['https://unsplash.com/photos/wtIPKwwYGOU/download?ixid=M3w2NDM0Nzl8MHwxfHNlYXJjaHwxfHwqKktleXdvcmRzJTNBKiolMEEtJTIwWW91bmclMjBib3klMEEtJTIwSm95ZnVsJTIwcGxheSUwQS0lMjBMdXNoJTIwZ3JlZW4lMjB0cmVlJTBBLSUyMFN1bmxpdCUyMHBhcmslMEEtJTIwQ2xpbWJpbmclMjB0cmVldG9wJTBBLSUyMEhhcHBpbmVzcyUwQS0lMjBWaWJyYW50JTIwcmVkJTIwYXBwbGVzJTBBLSUyMFNvZnQlMjBzdW5saWdodCUwQS0lMjBEYXBwbGVkJTIwc2hhZG93cyUwQS0lMjBDaGlsZGhvb2QlMjBqb3klMEEtJTIwRnJpZW5kc2hpcCUyMHdpdGglMjBuYXR1cmUlMEEtJTIwQ2FtZXJhJTIwc2V0dGluZ3MlMEEtJTIwNTBtbSUyMGxlbnMlMEEtJTIwZiUyRjIuOCUyMGFwZXJ0dXJlJTBBLSUyMElTTyUyMDEwMCUwQS0lMjAxJTJGMjAwcyUyMHNodXR0ZXIlMjBzcGVlZCUwQS0lMjBTaGFycCUyMGRldGFpbHMlMEEtJTIwU29mdCUyMGJhY2tncm91bmQlMjBibHVyJTBBJTBBKipBZGRpdGlvbmFsJTIwS2V5d29yZHMlM0EqKiUwQS0lMjBPdXRkb29yJTIwYWR2ZW50dXJlJTBBLSUyME5hdHVyZSUwQS0lMjBGYW1pbHklMEEtJTIwU2NlbmljJTIwYmVhdXR5JTBBLSUyMFBsYXlmdWwlMjBpbm5vY2VuY2UlMEEtJTIwTGlnaHQlMjBmaWx0ZXJpbmclMjB0aHJvdWdoJTIwbGVhdmVzJTBBLSUyMENoaWxkcmVuJTIwaW4lMjBuYXR1cmUlMEEtJTIwR3JlZW5lcnklMEEtJTIwRnJ1aXQlMjB0cmVlcyUwQS0lMjBTdW5saWdodCUyMGVmZmVjdHMlMEElMEEqKlNlYXJjaCUyMFNlbnRlbmNlJTNBKiolMEElMjJZb3VuZyUyMGJveSUyMGpveWZ1bGx5JTIwY2xpbWJpbmclMjBhJTIwbHVzaCUyMGdyZWVuJTIwdHJlZSUyMHdpdGglMjB2aWJyYW50JTIwcmVkJTIwYXBwbGVzJTIwaW4lMjBhJTIwc3VubGl0JTIwcGFyayUyQyUyMGNhcHR1cmluZyUyMGNoaWxkaG9vZCUyMGpveSUyMGFuZCUyMG5hdHVyZSUyN3MlMjBiZWF1dHkuJTIyfGVufDB8fHx8MTcyNDQ5MDEzMXww']"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "keywords = analyze_text_for_keywords(PROMPT)\n",
        "\n",
        "fetch_unsplash_images(keywords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "mJWbJ6ERn12m",
        "outputId": "f5f7ce59-f6c6-4ad0-a51c-e68b6a84ec17"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'**Keywords:**\\n- Young boy\\n- Joyful play\\n- Lush green tree\\n- Sunlit park\\n- Climbing treetop\\n- Happiness\\n- Vibrant red apples\\n- Soft sunlight\\n- Dappled shadows\\n- Childhood joy\\n- Friendship with nature\\n- Camera settings\\n- 50mm lens\\n- f/2.8 aperture\\n- ISO 100\\n- 1/200s shutter speed\\n- Sharp details\\n- Soft background blur\\n\\n**Additional Keywords:**\\n- Outdoor adventure\\n- Nature\\n- Family\\n- Scenic beauty\\n- Playful innocence\\n- Light filtering through leaves\\n- Children in nature\\n- Greenery\\n- Fruit trees\\n- Sunlight effects\\n\\n**Search Sentence:**\\n\"Young boy joyfully climbing a lush green tree with vibrant red apples in a sunlit park, capturing childhood joy and nature\\'s beauty.\"'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "keywords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRmG9_IYrDv3"
      },
      "source": [
        "# Final Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2trtit224z7",
        "outputId": "384a0209-6f0b-47a6-9660-023f9b8dfd71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NgrokTunnel: \"https://1c27-35-237-199-106.ngrok-free.app\" -> \"http://localhost:8000\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [420]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:     117.219.57.84:0 - \"GET /status HTTP/1.1\" 200 OK\n",
            "INFO:     117.219.57.84:0 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
            "INFO:     117.219.57.84:0 - \"GET /status HTTP/1.1\" 200 OK\n",
            "INFO:     117.219.57.84:0 - \"GET /status HTTP/1.1\" 200 OK\n",
            "INFO:     117.219.57.84:0 - \"GET /status HTTP/1.1\" 200 OK\n",
            "INFO:     117.219.57.84:0 - \"GET /status HTTP/1.1\" 200 OK\n",
            "INFO:     117.219.57.84:0 - \"GET /status HTTP/1.1\" 200 OK\n",
            "INFO:     117.219.57.84:0 - \"GET /recommend_images?query=Chicago+police+ignore+warnings+about+press+freedom+at+DNC+protests%0AWe+warned+them%2C+in+print+and+on+the+radio%2C+that+dispersing+law-abiding+journalists+violates+the+First+Amendment.+They+did+it+anyway&use_ai=True HTTP/1.1\" 200 OK\n",
            "INFO:     117.219.57.84:0 - \"GET /status HTTP/1.1\" 200 OK\n",
            "INFO:     117.219.57.84:0 - \"GET /status HTTP/1.1\" 200 OK\n",
            "INFO:     117.219.57.84:0 - \"GET /recommend_images?query=Chicago+police+ignore+warnings+about+press+freedom+at+DNC+protests%0AWe+warned+them%2C+in+print+and+on+the+radio%2C+that+dispersing+law-abiding+journalists+violates+the+First+Amendment.+They+did+it+anyway&use_ai=False HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2024-08-22T18:46:35+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8000-15deb30e-245b-4579-bdee-b6b3bfd95ea9 acceptErr=\"failed to accept connection: Listener closed\"\n",
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [420]\n"
          ]
        }
      ],
      "source": [
        "import nest_asyncio\n",
        "import uvicorn\n",
        "from fastapi import FastAPI, Query\n",
        "from fastapi.responses import JSONResponse, FileResponse\n",
        "from typing import Optional\n",
        "import openai\n",
        "from pyunsplash import PyUnsplash\n",
        "from pyngrok import ngrok\n",
        "import openai\n",
        "\n",
        "ngrok_authToken = userdata.get('NGROCK')\n",
        "ngrok.set_auth_token(ngrok_authToken)\n",
        "\n",
        "# Patch the event loop\n",
        "nest_asyncio.apply()\n",
        "\n",
        "app = FastAPI()\n",
        "client = OpenAI(\n",
        "# This is the default and can be omitted\n",
        "api_key=userdata.get('OPENAI_KEY'),\n",
        ")\n",
        "# Set your OpenAI AP\n",
        "unsplash_api_key = userdata.get('unsplash_api_key')\n",
        "\n",
        "pu = PyUnsplash(api_key=unsplash_api_key)\n",
        "\n",
        "def analyze_text_for_keywords(content: str):\n",
        "    \"\"\"\n",
        "    Analyzes the provided text to extract keywords using the OpenAI API.\n",
        "    \"\"\"\n",
        "    client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=userdata.get('OPENAI_KEY'),\n",
        "    )\n",
        "    prompt = f\"Analyze the following text and generate a list of keywords: {content}\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a keyword extraction assistant,  Understand the context and its supposed to be used to find sutable images, add relevant additional keywords based on the scenario which can be used while searching the image. Write a sentence of the search term\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    keywords = response.choices[0].message\n",
        "    keywords = keywords.content\n",
        "\n",
        "    return keywords\n",
        "\n",
        "def generate_ai_image_prompt(content: str):\n",
        "    \"\"\"\n",
        "    Generates a detailed prompt for AI image generation based on the text content.\n",
        "    \"\"\"\n",
        "    prompt = f\"Create a detailed and specific image generation prompt for the following content: {content}\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a AI Image Prompt Generator. Provide Prompts to generate image in DALLE using Photo Realistic Images with real world lighting , ,  must be under 200 tokens in total only return just the prompt and no other text\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    imageprompt = response.choices[0].message\n",
        "    imageprompt = imageprompt.content\n",
        "    return imageprompt\n",
        "\n",
        "def generate_ai_image(PROMPT: str):\n",
        "    \"\"\"\n",
        "    Generates images using the OpenAI API based on the provided prompt.\n",
        "    \"\"\"\n",
        "    client = OpenAI(\n",
        "        # This is the default and can be omitted\n",
        "        api_key=userdata.get('OPENAI_KEY'),\n",
        "        )\n",
        "    response = client.images.generate(\n",
        "        prompt=PROMPT,\n",
        "        n=2,\n",
        "        size=\"512x512\"\n",
        "    )\n",
        "    url = response.data[0].url\n",
        "    return url\n",
        "\n",
        "def fetch_unsplash_images(keywords: str):\n",
        "    \"\"\"\n",
        "    Fetches images from Unsplash based on the provided keywords using PyUnsplash.\n",
        "    \"\"\"\n",
        "    #loop through the list and get the images\n",
        "    search = pu.search(type_=\"photos\", query=keywords, per_page=1)\n",
        "    images = [photo.link_download for photo in search.entries]\n",
        "    return images[0]\n",
        "\n",
        "@app.get(\"/status\")\n",
        "async def status_check():\n",
        "    return JSONResponse(content={\"status\": \"API is running\"})\n",
        "\n",
        "@app.get(\"/recommend_images\")\n",
        "async def recommend_images(query: Optional[str] = Query(None, description=\"Query string for image recommendation\"),\n",
        "                           use_ai: Optional[bool] = Query(False, description=\"Use AI to generate images\")):\n",
        "    if query:\n",
        "      if use_ai:\n",
        "            PROMPT = generate_ai_image_prompt(query)\n",
        "            IMAGE_URL = generate_ai_image(PROMPT)\n",
        "            #return JSONResponse(content={\"url\": IMAGE_URL})\n",
        "            return JSONResponse(IMAGE_URL)\n",
        "      else:\n",
        "            keywords = analyze_text_for_keywords(query)\n",
        "            images = fetch_unsplash_images(keywords)\n",
        "            return JSONResponse(images)\n",
        "            # return JSONResponse(content={\"keywords\": keywords, \"images\": images})\n",
        "    else:\n",
        "        image_path = \"/content/image1.png\"  # Replace with logic to select the appropriate image\n",
        "        return FileResponse(image_path, media_type=\"image/png\")\n",
        "\n",
        "\n",
        "\n",
        "public_url = ngrok.connect(8000)\n",
        "print(public_url)\n",
        "\n",
        "# Run the Uvicorn server\n",
        "uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fks9nnxHB1Xh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
